"""
Ultimate API server fÃ¼r DLH Chatbot - BEST OF BOTH WORLDS VERSION
Combines:
- System Prompt for guaranteed links (new)
- Metadata subject search (new)
- Sonnet 4.5 (new)
- Overview URL prioritization (old, essential!)
- Event chronological sorting (old, essential!)
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Optional, Dict, Tuple
import json
import os
import re
import uvicorn
from anthropic import Anthropic
from dotenv import load_dotenv
from datetime import datetime, timedelta
from collections import Counter

# Load environment variables
load_dotenv()

# Initialize FastAPI app
app = FastAPI(
    title="DLH Chatbot API (Best of Both Worlds)",
    description="System Prompt + Metadata Search + Overview Priority",
    version="4.0.0"
)

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Initialize Anthropic client
anthropic_client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))

# Load and preprocess data
def load_and_preprocess_data():
    """Lade und bereite Daten mit verbesserter Struktur vor"""
    try:
        file_path = 'processed/processed_chunks.json'
        
        print(f"ðŸ” Attempting to load data from: {file_path}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            chunks = json.load(f)
        
        print(f"âœ… Successfully loaded {len(chunks)} chunks from {file_path}")
        
        # Erstelle Index fÃ¼r schnellere Suche
        keyword_index = {}
        url_index = {}
        subject_index = {}
        
        for i, chunk in enumerate(chunks):
            # URL-basierter Index
            url = chunk['metadata'].get('source', '').lower()
            if url not in url_index:
                url_index[url] = []
            url_index[url].append(i)
            
            # FÃ¤cher-Index aus Metadaten
            faecher = chunk['metadata'].get('fÃ¤cher', [])
            if faecher:
                for fach in faecher:
                    fach_lower = fach.lower()
                    if fach_lower not in subject_index:
                        subject_index[fach_lower] = []
                    subject_index[fach_lower].append(i)
            
            # Keyword-Index
            content = chunk['content'].lower()
            important_terms = [
                'fobizz', 'genki', 'innovationsfonds', 'cop', 'cops',
                'vernetzung', 'workshop', 'weiterbildung', 'kuratiert',
                'impuls', 'termin', 'anmeldung', 'lunch', 'learn',
                'impuls-workshop', 'impulsworkshop', 'veranstaltung', 'event',
                'chemie', 'physik', 'biologie', 'mathematik', 'informatik',
                'deutsch', 'englisch', 'franzÃ¶sisch', 'italienisch', 'spanisch',
                'geschichte', 'geografie', 'wirtschaft', 'recht', 'philosophie'
            ]
            
            for term in important_terms:
                if term in content:
                    if term not in keyword_index:
                        keyword_index[term] = []
                    keyword_index[term].append(i)
        
        print(f"ðŸ” Indexed {len(keyword_index)} keywords")
        print(f"ðŸ“š Indexed {len(subject_index)} subjects in metadata")
        
        return chunks, keyword_index, url_index, subject_index
    except Exception as e:
        print(f"âŒ Error loading data: {e}")
        import traceback
        traceback.print_exc()
        return [], {}, {}, {}

# Global data storage
CHUNKS, KEYWORD_INDEX, URL_INDEX, SUBJECT_INDEX = load_and_preprocess_data()

class QuestionRequest(BaseModel):
    question: str
    language: Optional[str] = "de"
    max_sources: Optional[int] = 5

class Source(BaseModel):
    url: str
    title: str
    snippet: str

class AnswerResponse(BaseModel):
    question: str
    answer: str
    sources: List[Source]

def extract_dates_from_text(text: str) -> List[Tuple[datetime, str]]:
    """Extrahiere Daten aus Text - unterstÃ¼tzt auch abgekÃ¼rzte Monatsnamen"""
    dates_found = []
    
    month_map_full = {
        'januar': 1, 'februar': 2, 'mÃ¤rz': 3, 'april': 4,
        'mai': 5, 'juni': 6, 'juli': 7, 'august': 8,
        'september': 9, 'oktober': 10, 'november': 11, 'dezember': 12
    }
    
    month_map_abbr = {
        'jan': 1, 'feb': 2, 'mÃ¤r': 3, 'mÃ¤rz': 3, 'mrz': 3, 'apr': 4,
        'mai': 5, 'jun': 6, 'jul': 7, 'aug': 8,
        'sep': 9, 'sept': 9, 'okt': 10, 'nov': 11, 'dez': 12
    }
    
    patterns = [
        (r'(\d{1,2})\.(\d{1,2})\.(\d{2,4})', 'numeric'),
        (r'(\d{1,2})\.\s*(Januar|Februar|MÃ¤rz|April|Mai|Juni|Juli|August|September|Oktober|November|Dezember)\s*(\d{4})', 'full_month'),
        (r'(\d{1,2})\.?\s+(Jan\.?|Feb\.?|MÃ¤r\.?|MÃ¤rz\.?|Mrz\.?|Apr\.?|Mai\.?|Jun\.?|Jul\.?|Aug\.?|Sep\.?|Sept\.?|Okt\.?|Nov\.?|Dez\.?)\s+(\d{4})', 'abbr_month'),
    ]
    
    # Pattern 1: DD.MM.YYYY
    for match in re.finditer(patterns[0][0], text):
        try:
            day = int(match.group(1))
            month = int(match.group(2))
            year_str = match.group(3)
            year = int(year_str) if len(year_str) == 4 else (2000 + int(year_str))
            
            date_obj = datetime(year, month, day)
            start = max(0, match.start() - 100)
            end = min(len(text), match.end() + 100)
            context = text[start:end].strip()
            
            dates_found.append((date_obj, context, match.group(0)))
        except ValueError:
            continue
    
    # Pattern 2: DD. Monat YYYY
    for match in re.finditer(patterns[1][0], text, re.IGNORECASE):
        try:
            day = int(match.group(1))
            month_name = match.group(2).lower()
            month = month_map_full.get(month_name)
            year = int(match.group(3))
            
            if month:
                date_obj = datetime(year, month, day)
                start = max(0, match.start() - 100)
                end = min(len(text), match.end() + 100)
                context = text[start:end].strip()
                
                dates_found.append((date_obj, context, match.group(0)))
        except ValueError:
            continue
    
    # Pattern 3: DD Mon. YYYY (abbreviated)
    for match in re.finditer(patterns[2][0], text, re.IGNORECASE):
        try:
            day = int(match.group(1))
            month_abbr = match.group(2).lower().replace('.', '').strip()
            month = month_map_abbr.get(month_abbr)
            year = int(match.group(3))
            
            if month:
                date_obj = datetime(year, month, day)
                start = max(0, match.start() - 100)
                end = min(len(text), match.end() + 100)
                context = text[start:end].strip()
                
                dates_found.append((date_obj, context, match.group(0)))
        except ValueError:
            continue
    
    return dates_found

def sort_events_chronologically(chunks: List[Dict], current_date: datetime = None) -> Dict[str, List[Dict]]:
    """Sortiere Events chronologisch"""
    if current_date is None:
        current_date = datetime.now()
    
    future_events = []
    past_events = []
    no_date_events = []
    
    for chunk in chunks:
        content = chunk['content']
        dates = extract_dates_from_text(content)
        
        if dates:
            dates.sort(key=lambda x: x[0])
            earliest_date = dates[0][0]
            
            event_info = {
                'chunk': chunk,
                'date': earliest_date,
                'date_str': dates[0][2],
                'all_dates': dates,
                'context': dates[0][1]
            }
            
            if earliest_date.date() < current_date.date():
                past_events.append(event_info)
            else:
                future_events.append(event_info)
        else:
            no_date_events.append({'chunk': chunk})
    
    future_events.sort(key=lambda x: x['date'])
    past_events.sort(key=lambda x: x['date'], reverse=True)
    
    return {
        'future_events': future_events,
        'past_events': past_events,
        'no_date_events': no_date_events
    }

def extract_query_intent(query: str) -> Dict[str, any]:
    """Analysiere die Absicht der Frage"""
    query_lower = query.lower()
    
    innovationsfonds_terms = [
        'innovationsfonds', 'innovationsprojekt', 'innovationsprojekte',
        'projekt', 'projekte', 'welche projekte'
    ]
    
    intent = {
        'is_date_query': any(term in query_lower for term in ['heute', 'morgen', 'termin', 'wann', 'datum', 'zeit', 'event', 'veranstaltung', 'nÃ¤chste', 'kommende']),
        'is_how_to': any(term in query_lower for term in ['wie', 'anleitung', 'tutorial', 'schritte']),
        'is_definition': any(term in query_lower for term in ['was ist', 'was sind', 'definition', 'bedeutung']),
        'wants_list': any(term in query_lower for term in ['welche', 'liste', 'alle', 'Ã¼berblick', 'Ã¼bersicht']),
        'wants_contact': any(term in query_lower for term in ['kontakt', 'anmeldung', 'email', 'telefon', 'anmelden']),
        'is_innovationsfonds_query': any(term in query_lower for term in innovationsfonds_terms),
        'topic_keywords': [],
        'subject_keywords': []
    }
    
    topics = {
        'fobizz': ['fobizz', 'to teach', 'to-teach'],
        'genki': ['genki', 'gen ki', 'gen-ki'],
        'innovationsfonds': ['innovationsfonds', 'innovation', 'projekt'],
        'workshop': ['workshop', 'impuls', 'veranstaltung', 'impuls-workshop', 'impulsworkshop', 'event'],
        'cop': ['cop', 'cops', 'community', 'practice'],
        'weiterbildung': ['weiterbildung', 'fortbildung', 'kurs', 'schulung'],
        'vernetzung': ['vernetzung', 'netzwerk', 'austausch'],
        'kuratiert': ['kuratiert', 'kuratiertes', 'sammlung']
    }
    
    subjects = {
        'chemie': ['chemie'],
        'physik': ['physik'],
        'biologie': ['biologie'],
        'mathematik': ['mathematik', 'mathe'],
        'informatik': ['informatik'],
        'deutsch': ['deutsch'],
        'englisch': ['englisch'],
        'franzÃ¶sisch': ['franzÃ¶sisch'],
        'italienisch': ['italienisch'],
        'spanisch': ['spanisch'],
        'geschichte': ['geschichte'],
        'geografie': ['geografie', 'geographie'],
        'wirtschaft': ['wirtschaft'],
        'recht': ['recht'],
        'philosophie': ['philosophie']
    }
    
    for topic, keywords in topics.items():
        if any(kw in query_lower for kw in keywords):
            intent['topic_keywords'].append(topic)
    
    for subject, keywords in subjects.items():
        if any(kw in query_lower for kw in keywords):
            intent['subject_keywords'].append(subject)
    
    return intent

def advanced_search(query: str, max_results: int = 10) -> List[Dict]:
    """BEST OF BOTH: Metadata search + Overview URL prioritization"""
    intent = extract_query_intent(query)
    query_lower = query.lower()
    query_words = set(query_lower.split())
    
    results = []
    
    if 'impuls' in query_lower and 'workshop' in query_lower:
        intent['topic_keywords'].append('impulsworkshop')
    
    # FROM OLD VERSION: Overview URL Prioritization!
    overview_urls = [
        'https://dlh.zh.ch/',
        'https://dlh.zh.ch',
        'https://dlh.zh.ch/home/impuls-workshops',
        'https://dlh.zh.ch/home/aktuelle-termine',
        'https://dlh.zh.ch/home/innovationsfonds/projektvorstellungen/uebersicht'
    ]
    
    # PRIORITÃ„T 1: Bei Event/Workshop-Anfragen die Ãœbersichtsseiten ZUERST! (Score 150)
    if any(kw in ['workshop', 'veranstaltung'] for kw in intent['topic_keywords']):
        print(f"ðŸ” Prioritizing overview pages for workshop/event query")
        for overview_url in overview_urls:
            if overview_url in URL_INDEX:
                for idx in URL_INDEX[overview_url][:2]:
                    if idx < len(CHUNKS):
                        results.append((150, CHUNKS[idx]))
                        print(f"   âœ" Added overview {overview_url} with score 150")
    
    # PRIORITÃ„T 2: Metadaten-basierte Fachsuche fÃ¼r Innovationsfonds (Score 200)
    if intent['is_innovationsfonds_query'] and intent['subject_keywords']:
        print(f"ðŸ” Searching for Innovationsfonds projects in subjects: {intent['subject_keywords']}")
        for subject in intent['subject_keywords']:
            if subject in SUBJECT_INDEX:
                print(f"   Found {len(SUBJECT_INDEX[subject])} projects in {subject} via metadata")
                for idx in SUBJECT_INDEX[subject]:
                    if idx < len(CHUNKS):
                        chunk = CHUNKS[idx]
                        if 'projektvorstellungen' in chunk['metadata'].get('source', '').lower():
                            if not any(r[1] == chunk for r in results):
                                results.append((200, chunk))
    
    # PRIORITÃ„T 3: Allgemeine Innovationsfonds-Anfragen (Score 150)
    elif intent['is_innovationsfonds_query']:
        for url, indices in URL_INDEX.items():
            if 'projektvorstellungen' in url:
                for idx in indices:
                    if idx < len(CHUNKS):
                        chunk = CHUNKS[idx]
                        if not any(r[1] == chunk for r in results):
                            results.append((150, chunk))
    
    # 4. URL-Treffer (vermeidet overview_urls Duplikate!)
    for topic in intent['topic_keywords']:
        for url, indices in URL_INDEX.items():
            if topic in url and url not in overview_urls:
                for idx in indices[:3]:
                    if idx < len(CHUNKS):
                        chunk = CHUNKS[idx]
                        if not any(r[1] == chunk for r in results):
                            results.append((100, chunk))
    
    # 5. Keyword-Index-Suche
    for topic in intent['topic_keywords'] + intent['subject_keywords']:
        if topic in KEYWORD_INDEX:
            for idx in KEYWORD_INDEX[topic][:5]:
                if idx < len(CHUNKS):
                    chunk = CHUNKS[idx]
                    if not any(r[1] == chunk for r in results):
                        results.append((80, chunk))
    
    # 6. Textsuche
    for i, chunk in enumerate(CHUNKS):
        if len(results) > max_results * 3:
            break
            
        content_lower = chunk['content'].lower()
        score = 0
        
        if 'projektvorstellungen' in chunk['metadata'].get('source', '').lower():
            score += 30
        
        if len(query_words) > 1:
            words_list = query_lower.split()
            for j in range(len(words_list) - 1):
                phrase = f"{words_list[j]} {words_list[j+1]}"
                if phrase in content_lower:
                    score += 25
        
        content_words = set(content_lower.split())
        matching_words = query_words & content_words
        score += len(matching_words) * 5
        
        if intent['is_date_query'] and any(d in content_lower for d in ['2024', '2025', '2026', 'uhr', 'datum', 'termin']):
            score += 20
        
        if score > 10 and not any(r[1] == chunk for r in results):
            results.append((score, chunk))
    
    results.sort(key=lambda x: x[0], reverse=True)
    
    print(f"ðŸ“Š Search results before deduplication: {len(results)}")
    if results:
        print(f"   Top 5 scores: {[r[0] for r in results[:5]]}")
    
    # URL-basierte Deduplizierung
    final_results = []
    seen_urls = set()
    url_count = Counter()
    
    for score, chunk in results:
        url = chunk['metadata'].get('source', '')
        is_project_page = 'projektvorstellungen' in url.lower() and 'uebersicht' in url.lower() and any(char.isdigit() for char in url.split('/')[-1])
        
        if is_project_page:
            if url not in seen_urls:
                final_results.append(chunk)
                seen_urls.add(url)
        else:
            if url_count[url] < 2:
                final_results.append(chunk)
                url_count[url] += 1
            
        if len(final_results) >= max_results:
            break
    
    print(f"âœ… Final results: {len(final_results)}")
    
    return final_results

def create_enhanced_prompt(question: str, chunks: List[Dict], intent: Dict) -> str:
    """Erstelle Prompt - Formatierung ist im System Prompt"""
    
    current_date = datetime.now()
    current_date_str = current_date.strftime('%d.%m.%Y')
    
    # Event-Sortierung von gestern!
    if intent['is_date_query'] or any(keyword in ['workshop', 'veranstaltung'] for keyword in intent['topic_keywords']):
        sorted_events = sort_events_chronologically(chunks, current_date)
        
        context_parts = []
        
        if sorted_events['future_events']:
            context_parts.append("=== KOMMENDE VERANSTALTUNGEN (chronologisch sortiert) ===")
            for event in sorted_events['future_events']:
                days_until = (event['date'].date() - current_date.date()).days
                context_parts.append(f"\nðŸ“… DATUM: {event['date'].strftime('%d.%m.%Y (%A)')} (in {days_until} Tagen)")
                context_parts.append(f"Titel: {event['chunk']['metadata'].get('title', 'Unbekannt')}")
                context_parts.append(f"Quelle: {event['chunk']['metadata'].get('source', 'Unbekannt')}")
                context_parts.append(event['chunk']['content'][:400])
                context_parts.append("---")
        
        if sorted_events['past_events']:
            context_parts.append("\n\n=== VERGANGENE VERANSTALTUNGEN ===")
            for event in sorted_events['past_events'][:5]:
                days_ago = (current_date.date() - event['date'].date()).days
                context_parts.append(f"\nðŸ“… DATUM: {event['date'].strftime('%d.%m.%Y (%A)')} (vor {days_ago} Tagen - BEREITS VORBEI)")
                context_parts.append(f"Titel: {event['chunk']['metadata'].get('title', 'Unbekannt')}")
                context_parts.append(f"Quelle: {event['chunk']['metadata'].get('source', 'Unbekannt')}")
                context_parts.append(event['chunk']['content'][:400])
                context_parts.append("---")
        
        if sorted_events['no_date_events']:
            context_parts.append("\n\n=== WEITERE INFORMATIONEN ===")
            for item in sorted_events['no_date_events']:
                context_parts.append(f"\nTitel: {item['chunk']['metadata'].get('title', 'Unbekannt')}")
                context_parts.append(f"Quelle: {item['chunk']['metadata'].get('source', 'Unbekannt')}")
                context_parts.append(item['chunk']['content'][:400])
                context_parts.append("---")
        
        context = "\n".join(context_parts)
        
        prompt = f"""Heutiges Datum: {current_date_str}

KONTEXT (chronologisch sortierte Veranstaltungen):
{context}

FRAGE: {question}

Beantworte die Frage. Zeige zukÃ¼nftige Events zuerst, chronologisch sortiert."""

    else:
        # Projekte
        context_parts = []
        for chunk in chunks:
            url = chunk['metadata'].get('source', 'Unbekannt')
            title = chunk['metadata'].get('title', 'Keine Beschreibung')
            faecher = chunk['metadata'].get('fÃ¤cher', [])
            
            context_parts.append(f"=== Projekt: {title} ===")
            context_parts.append(f"URL: {url}")
            if faecher:
                context_parts.append(f"FÃ¤cher: {', '.join(faecher)}")
            context_parts.append(chunk['content'][:400])
            context_parts.append("---\n")
        
        context = "\n".join(context_parts)
        
        if intent['is_innovationsfonds_query']:
            prompt = f"""KONTEXT (Innovationsfonds-Projekte mit URLs):
{context}

FRAGE: {question}

Zeige JEDEN Projekttitel als klickbaren Link (Format siehe System-Prompt)."""
        else:
            prompt = f"""KONTEXT:
{context}

FRAGE: {question}"""
    
    return prompt

@app.get("/")
async def root():
    return {
        "message": "DLH Chatbot API (Best of Both Worlds)",
        "status": "running" if len(CHUNKS) > 0 else "ERROR",
        "chunks_loaded": len(CHUNKS),
        "version": "4.0.0"
    }

@app.get("/health")
async def health_check():
    return {
        "status": "healthy" if len(CHUNKS) > 0 else "ERROR",
        "chunks_loaded": len(CHUNKS),
        "features": "System Prompt + Metadata Search + Overview Priority + Event Sorting"
    }

@app.post("/ask", response_model=AnswerResponse)
async def ask_question(request: QuestionRequest):
    """Beantworte Fragen"""
    
    if len(CHUNKS) == 0:
        raise HTTPException(status_code=500, detail="No data loaded")
    
    try:
        intent = extract_query_intent(request.question)
        
        print(f"\nðŸ” Query: {request.question}")
        print(f"   Intent: date={intent['is_date_query']}, innovationsfonds={intent['is_innovationsfonds_query']}")
        print(f"   Topics: {intent['topic_keywords']}, Subjects: {intent['subject_keywords']}")
        
        relevant_chunks = advanced_search(request.question, max_results=request.max_sources + 5)
        
        if not relevant_chunks:
            answer = f"<strong>Entschuldigung, ich konnte keine relevanten Informationen finden.</strong><br><br>"
            answer += "Besuchen Sie <a href='https://dlh.zh.ch' target='_blank'>dlh.zh.ch</a> fÃ¼r weitere Informationen."
            
            return AnswerResponse(question=request.question, answer=answer, sources=[])
        
        prompt = create_enhanced_prompt(request.question, relevant_chunks, intent)
        
        # System Prompt fÃ¼r garantierte Formatierung!
        system_prompt = """Du bist der offizielle DLH Chatbot. Antworte auf Deutsch mit HTML-Formatierung.

KRITISCHE REGEL - PROJEKTTITEL MÃœSSEN IMMER KLICKBARE LINKS SEIN:
Format: <strong><a href="VOLLSTÃ„NDIGE-URL" target="_blank">Projekttitel</a></strong><br>
Beschreibung in 1-2 SÃ¤tzen<br><br>

HTML-Tags:
- <br> = Zeilenumbruch
- <br><br> = Absatz
- <strong> = Ãœberschriften
- <a href="URL" target="_blank"> = Links
- NIEMALS Markdown (*, #, _)

BEISPIEL:
<strong><a href="https://dlh.zh.ch/home/innovationsfonds/projektvorstellungen/uebersicht/1042-histoswiss" target="_blank">HistoSwiss</a></strong><br>
InterdisziplinÃ¤res Geschichtsprojekt mit digitalen Werkzeugen<br><br>"""

        try:
            response = anthropic_client.messages.create(
                model="claude-sonnet-4-5-20250929",  # Sonnet 4.5!
                max_tokens=2500,
                temperature=0.3,
                system=system_prompt,
                messages=[{"role": "user", "content": prompt}]
            )
            
            answer = response.content[0].text
            
        except Exception as claude_error:
            print(f"ðŸ”´ Claude API Error: {claude_error}")
            
            answer = "<strong>Entschuldigung, ich kann gerade nicht auf die KI zugreifen.</strong><br><br>"
            for i, chunk in enumerate(relevant_chunks[:3]):
                title = chunk['metadata'].get('title', 'Information')
                url = chunk['metadata'].get('source', '')
                answer += f"<strong><a href='{url}' target='_blank'>{title}</a></strong><br><br>"
        
        # Format sources
        sources = []
        seen_urls = set()
        for chunk in relevant_chunks[:request.max_sources]:
            url = chunk['metadata']['source']
            if url not in seen_urls:
                sources.append(Source(
                    url=url,
                    title=chunk['metadata'].get('title', 'DLH Seite'),
                    snippet=chunk['content'][:150] + "..."
                ))
                seen_urls.add(url)
        
        return AnswerResponse(question=request.question, answer=answer, sources=sources)
        
    except Exception as e:
        print(f"Error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

try:
    app.mount("/static", StaticFiles(directory="frontend"), name="static")
except Exception as e:
    print(f"Warning: Could not mount static files: {e}")

if __name__ == "__main__":
    print("\nðŸš€ Starting DLH Chatbot API (BEST OF BOTH WORLDS)...")
    print(f"ðŸ“š Loaded {len(CHUNKS)} chunks")
    print(f"ðŸ” Indexed {len(KEYWORD_INDEX)} keywords")
    print(f"ðŸ“š Indexed {len(SUBJECT_INDEX)} subjects")
    print("âœ¨ Features:")
    print("   âœ… System Prompt (guaranteed links)")
    print("   âœ… Metadata subject search")
    print("   âœ… Overview URL prioritization")
    print("   âœ… Event chronological sorting")
    print("   âœ… Sonnet 4.5")
    print("\nâœ… ALL FEATURES ENABLED!\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
